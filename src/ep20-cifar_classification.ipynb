{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 实战：CIFAR分类问题\n",
   "id": "f8fb20f0a60d9aca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:07:56.759520Z",
     "start_time": "2024-07-20T09:07:56.745258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as data_loader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "id": "ab285700549225ab",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 准备数据集\n",
   "id": "f21ebf017d9f8923"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:07:58.273536Z",
     "start_time": "2024-07-20T09:07:56.791293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root='../dataset',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# 测试数据集\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root='../dataset',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# 信息展示\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "print(f'>> len of train data: {train_data_size}; len of test data: {test_data_size}')\n"
   ],
   "id": "56a8b661386ce32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      ">> len of train data: 50000; len of test data: 10000\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:07:58.304613Z",
     "start_time": "2024-07-20T09:07:58.275623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 利用DataLoader加载数据集\n",
    "train_loader = data_loader.DataLoader(\n",
    "    train_data,\n",
    "    64,\n",
    "    True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 加载测试数据集\n",
    "test_loader = data_loader.DataLoader(\n",
    "    test_data,\n",
    "    64,\n",
    "    True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n"
   ],
   "id": "37eecfd951aad597",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 搭建神经网络\n",
   "id": "fd6a6f20aa6a4bcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:07:58.319837Z",
     "start_time": "2024-07-20T09:07:58.306781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "类定义内容建议新建一个文件单独保存\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TianNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ],
   "id": "13c8532a4f117c8d",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "验证网络准确性\n",
   "id": "91aad822464dcabb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:07:58.351057Z",
     "start_time": "2024-07-20T09:07:58.321909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tiannet = TianNet()\n",
    "input = torch.ones((64, 3, 32, 32))\n",
    "output = tiannet(input)\n",
    "\n",
    "print(f'>> output shape: {output.shape}')\n"
   ],
   "id": "cab145405f28240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> output shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练神经网络\n",
   "id": "e809bd0ec78659cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T09:27:07.626448Z",
     "start_time": "2024-07-20T09:21:46.774686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 创建神经网络\n",
    "tiannet = TianNet()\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(tiannet.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的参数\n",
    "total_train_step = 0  # 记录训练次数\n",
    "total_test_step = 0  # 记录测试次数\n",
    "epochs = 10  # 训练轮数\n",
    "\n",
    "# 添加TensorBoard\n",
    "writer = SummaryWriter('../logs/cifiar_classification')\n",
    "\n",
    "# 开始训练\n",
    "for i in range(epochs):\n",
    "    print(f'>> epoch {i} starts...')\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tiannet.train()  # 【可选】设置模型到训练状态\n",
    "    for data in train_loader:\n",
    "        # 获取数据\n",
    "        imgs, labels = data\n",
    "        \n",
    "        # 放入模型\n",
    "        y_hat = tiannet(imgs)  # 计算y_hat\n",
    "        \n",
    "        # 训练参数\n",
    "        loss = loss_fn(y_hat, labels)  # 计算损失\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 优化参数\n",
    "        \n",
    "        # 记录新的训练次数\n",
    "        total_train_step += 1\n",
    "        \n",
    "        # 保存数据\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(f'\\ttrain step {total_train_step} times, loss: {loss.item()}')\n",
    "            writer.add_scalar('train loss', loss.item(), global_step=total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    tiannet.eval()  # 【可选】设置模型到测试状态\n",
    "    # 准确率记录\n",
    "    total_accuracy = 0  # 总正确率\n",
    "    total_test_loss = 0  # 总损失值\n",
    "    with torch.no_grad():  # 这个函数关闭了梯度调整的设置\n",
    "        for data in test_loader:\n",
    "            imgs, targets = data  # 获取数据\n",
    "            \n",
    "            outputs = tiannet(imgs)  # 使用模型预测输出\n",
    "            \n",
    "            loss = loss_fn(outputs, targets)  # y_hat与y进行对比，计算损失函数\n",
    "            total_test_loss = total_test_loss + loss.item()  # 损失函数加和，用于比较每一轮训练中的损失函数变化\n",
    "            \n",
    "            # 计算正确率\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()  # 一次测试中正确的数量\n",
    "            total_accuracy = total_accuracy + accuracy  # 总体正确数量加和\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f'>> total loss on test dataset: {total_test_loss}')  # 打印损失\n",
    "    print(f'>> total accuracy on test dataset: {total_accuracy / test_data_size}')  # 正确数量减去总体数量\n",
    "    \n",
    "    # 保存结果\n",
    "    writer.add_scalar('test loss', total_test_loss, global_step=total_test_step)  # 添加记录\n",
    "    writer.add_scalar('test accuracy', total_accuracy / test_data_size, global_step=total_test_step)  # 添加正确率记录\n",
    "    \n",
    "    # 更新数据\n",
    "    total_test_step += 1  # 更新步骤值\n",
    "\n",
    "    # 保存每一轮训练后的模型\n",
    "    torch.save(tiannet.state_dict(), f'../saved_models/cifar_model/tiannet_epoch_{i}.pth')\n",
    "    print('>> model saved.')\n",
    "\n",
    "writer.close()\n"
   ],
   "id": "aaa54fafe5acdef4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> epoch 0 starts...\n",
      "\ttrain step 100 times, loss: 2.3124547004699707\n",
      "\ttrain step 200 times, loss: 2.309232711791992\n",
      "\ttrain step 300 times, loss: 2.3025665283203125\n",
      "\ttrain step 400 times, loss: 2.243960380554199\n",
      "\ttrain step 500 times, loss: 2.212387800216675\n",
      "\ttrain step 600 times, loss: 2.0937037467956543\n",
      "\ttrain step 700 times, loss: 2.1072473526000977\n",
      ">> total loss on test dataset: 310.36159217357635\n",
      ">> total accuracy on test dataset: 0.2937999963760376\n",
      ">> model saved.\n",
      ">> epoch 1 starts...\n",
      "\ttrain step 800 times, loss: 2.076301097869873\n",
      "\ttrain step 900 times, loss: 2.012960195541382\n",
      "\ttrain step 1000 times, loss: 1.9506627321243286\n",
      "\ttrain step 1100 times, loss: 1.9443750381469727\n",
      "\ttrain step 1200 times, loss: 1.936598300933838\n",
      "\ttrain step 1300 times, loss: 1.7769330739974976\n",
      "\ttrain step 1400 times, loss: 1.7838813066482544\n",
      "\ttrain step 1500 times, loss: 1.7575141191482544\n",
      ">> total loss on test dataset: 274.60762095451355\n",
      ">> total accuracy on test dataset: 0.38429999351501465\n",
      ">> model saved.\n",
      ">> epoch 2 starts...\n",
      "\ttrain step 1600 times, loss: 1.8260835409164429\n",
      "\ttrain step 1700 times, loss: 1.640305995941162\n",
      "\ttrain step 1800 times, loss: 1.8090579509735107\n",
      "\ttrain step 1900 times, loss: 1.6933672428131104\n",
      "\ttrain step 2000 times, loss: 1.6408582925796509\n",
      "\ttrain step 2100 times, loss: 1.616631269454956\n",
      "\ttrain step 2200 times, loss: 1.5915158987045288\n",
      "\ttrain step 2300 times, loss: 1.7179700136184692\n",
      ">> total loss on test dataset: 270.1795303821564\n",
      ">> total accuracy on test dataset: 0.37940001487731934\n",
      ">> model saved.\n",
      ">> epoch 3 starts...\n",
      "\ttrain step 2400 times, loss: 1.6126645803451538\n",
      "\ttrain step 2500 times, loss: 1.771199345588684\n",
      "\ttrain step 2600 times, loss: 1.4680358171463013\n",
      "\ttrain step 2700 times, loss: 1.4286483526229858\n",
      "\ttrain step 2800 times, loss: 1.312083125114441\n",
      "\ttrain step 2900 times, loss: 1.6598389148712158\n",
      "\ttrain step 3000 times, loss: 1.5869505405426025\n",
      "\ttrain step 3100 times, loss: 1.4254149198532104\n",
      ">> total loss on test dataset: 264.4592555761337\n",
      ">> total accuracy on test dataset: 0.4124000072479248\n",
      ">> model saved.\n",
      ">> epoch 4 starts...\n",
      "\ttrain step 3200 times, loss: 1.3788385391235352\n",
      "\ttrain step 3300 times, loss: 1.4910686016082764\n",
      "\ttrain step 3400 times, loss: 1.3783934116363525\n",
      "\ttrain step 3500 times, loss: 1.546876072883606\n",
      "\ttrain step 3600 times, loss: 1.5081982612609863\n",
      "\ttrain step 3700 times, loss: 1.6237984895706177\n",
      "\ttrain step 3800 times, loss: 1.5512210130691528\n",
      "\ttrain step 3900 times, loss: 1.3621786832809448\n",
      ">> total loss on test dataset: 249.11919331550598\n",
      ">> total accuracy on test dataset: 0.42820000648498535\n",
      ">> model saved.\n",
      ">> epoch 5 starts...\n",
      "\ttrain step 4000 times, loss: 1.4544620513916016\n",
      "\ttrain step 4100 times, loss: 1.085906982421875\n",
      "\ttrain step 4200 times, loss: 1.269906759262085\n",
      "\ttrain step 4300 times, loss: 1.3664933443069458\n",
      "\ttrain step 4400 times, loss: 1.3131623268127441\n",
      "\ttrain step 4500 times, loss: 1.3094924688339233\n",
      "\ttrain step 4600 times, loss: 1.5653189420700073\n",
      ">> total loss on test dataset: 211.0298249721527\n",
      ">> total accuracy on test dataset: 0.5231000185012817\n",
      ">> model saved.\n",
      ">> epoch 6 starts...\n",
      "\ttrain step 4700 times, loss: 1.3497653007507324\n",
      "\ttrain step 4800 times, loss: 1.4239683151245117\n",
      "\ttrain step 4900 times, loss: 1.382791519165039\n",
      "\ttrain step 5000 times, loss: 1.4553229808807373\n",
      "\ttrain step 5100 times, loss: 1.3596282005310059\n",
      "\ttrain step 5200 times, loss: 1.251065731048584\n",
      "\ttrain step 5300 times, loss: 1.1685484647750854\n",
      "\ttrain step 5400 times, loss: 1.0534062385559082\n",
      ">> total loss on test dataset: 220.37175923585892\n",
      ">> total accuracy on test dataset: 0.4993000030517578\n",
      ">> model saved.\n",
      ">> epoch 7 starts...\n",
      "\ttrain step 5500 times, loss: 1.2446810007095337\n",
      "\ttrain step 5600 times, loss: 1.45386803150177\n",
      "\ttrain step 5700 times, loss: 1.4386845827102661\n",
      "\ttrain step 5800 times, loss: 1.2562569379806519\n",
      "\ttrain step 5900 times, loss: 1.0144625902175903\n",
      "\ttrain step 6000 times, loss: 1.235443115234375\n",
      "\ttrain step 6100 times, loss: 1.1485825777053833\n",
      "\ttrain step 6200 times, loss: 1.355223298072815\n",
      ">> total loss on test dataset: 198.75120520591736\n",
      ">> total accuracy on test dataset: 0.5483999848365784\n",
      ">> model saved.\n",
      ">> epoch 8 starts...\n",
      "\ttrain step 6300 times, loss: 1.1689982414245605\n",
      "\ttrain step 6400 times, loss: 1.1201962232589722\n",
      "\ttrain step 6500 times, loss: 1.0306425094604492\n",
      "\ttrain step 6600 times, loss: 1.0722318887710571\n",
      "\ttrain step 6700 times, loss: 1.434184193611145\n",
      "\ttrain step 6800 times, loss: 1.0996254682540894\n",
      "\ttrain step 6900 times, loss: 1.480371356010437\n",
      "\ttrain step 7000 times, loss: 1.2316750288009644\n",
      ">> total loss on test dataset: 191.29675763845444\n",
      ">> total accuracy on test dataset: 0.567300021648407\n",
      ">> model saved.\n",
      ">> epoch 9 starts...\n",
      "\ttrain step 7100 times, loss: 1.2160331010818481\n",
      "\ttrain step 7200 times, loss: 0.8682637214660645\n",
      "\ttrain step 7300 times, loss: 1.0420923233032227\n",
      "\ttrain step 7400 times, loss: 1.1583904027938843\n",
      "\ttrain step 7500 times, loss: 1.0535560846328735\n",
      "\ttrain step 7600 times, loss: 1.2729183435440063\n",
      "\ttrain step 7700 times, loss: 0.988926351070404\n",
      "\ttrain step 7800 times, loss: 1.0301308631896973\n",
      ">> total loss on test dataset: 188.4737076163292\n",
      ">> total accuracy on test dataset: 0.5720000267028809\n",
      ">> model saved.\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 计算正确率\n",
   "id": "b73c0103a8d76556"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 伪造一个输出\n",
    "outputs = torch.tensor([\n",
    "    [0.1, 0.2],\n",
    "    [0.4, 0.3]\n",
    "])\n",
    "\n",
    "# 使用argmax()函数获取输出中的最大值，\n",
    "# 该方法可以用于从模型预测结果中找出预测类别。\n",
    "print(f'>> prediction classes: {outputs.argmax(dim=1)}')\n",
    "# 获取预测结果\n",
    "preds = outputs.argmax(dim=1)\n",
    "targets = torch.tensor([0, 1])\n",
    "print(f'>> comparison: {preds == targets}')\n",
    "print(f'>> get sum of compare result: {(preds == targets).sum()}')\n",
    "\n"
   ],
   "id": "b83e048a4a3c5106",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a715a4c4128545a7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
